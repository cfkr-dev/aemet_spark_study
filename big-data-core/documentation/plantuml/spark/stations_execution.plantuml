@startuml
participant "SparkQueriesCore" as SPARK_QUERIES_CORE
participant "StationsQueriesCore" as STATIONS_QUERIES_CORE
participant "SparkSessionCore" as SPARK_SESSION_CORE
participant "Storage" as STORAGE

SPARK_QUERIES_CORE -> STATIONS_QUERIES_CORE : execute()
activate STATIONS_QUERIES_CORE

group Station count evolution
    STATIONS_QUERIES_CORE -> SPARK_QUERIES_CORE : getStationCountByColumnInLapse(params)
    SPARK_QUERIES_CORE --> STATIONS_QUERIES_CORE : DataFrame
    STATIONS_QUERIES_CORE -> SPARK_SESSION_CORE : saveDataframeAsParquet(resultsDF, path)
    SPARK_SESSION_CORE -> STORAGE : write parquet
    STORAGE --> SPARK_SESSION_CORE : saved
    SPARK_SESSION_CORE --> STATIONS_QUERIES_CORE : saved
end

group Station count by state (2024)
    STATIONS_QUERIES_CORE -> SPARK_QUERIES_CORE : getStationCountByColumnInLapse(params)
    SPARK_QUERIES_CORE --> STATIONS_QUERIES_CORE : DataFrame
    STATIONS_QUERIES_CORE -> SPARK_SESSION_CORE : saveDataframeAsParquet(resultsDF, path)
    SPARK_SESSION_CORE -> STORAGE : write parquet
    STORAGE --> SPARK_SESSION_CORE : saved
    SPARK_SESSION_CORE --> STATIONS_QUERIES_CORE : saved
end

group Station count by altitude (2024)
    STATIONS_QUERIES_CORE -> SPARK_QUERIES_CORE : getStationsCountByParamIntervalsInALapse(params)
    SPARK_QUERIES_CORE --> STATIONS_QUERIES_CORE : DataFrame
    STATIONS_QUERIES_CORE -> SPARK_SESSION_CORE : saveDataframeAsParquet(resultsDF, path)
    SPARK_SESSION_CORE -> STORAGE : write parquet
    STORAGE --> SPARK_SESSION_CORE : saved
    SPARK_SESSION_CORE --> STATIONS_QUERIES_CORE : saved
end

STATIONS_QUERIES_CORE --> SPARK_QUERIES_CORE : done
deactivate STATIONS_QUERIES_CORE

@enduml
